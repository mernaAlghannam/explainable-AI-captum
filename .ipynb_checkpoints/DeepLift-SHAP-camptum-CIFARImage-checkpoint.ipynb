{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4853cca",
   "metadata": {},
   "source": [
    "**Computer Vision: Saliency Map for CIFAR Dataset** <br>\n",
    "Interpret the deep learning model result by looking on its gradients. <br>\n",
    "Method used in the code is Vanilla Gradient method. <br>\n",
    "There are multiple saliency methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185578ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\merna\\anaconda3\\envs\\pt\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-cfdc6380c211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pt\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\merna\\anaconda3\\envs\\pt\\lib\\site-packages\\torch\\lib\\caffe2_detectron_ops.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# Functional module contains helper functions\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40952826",
   "metadata": {},
   "source": [
    "**Set up the deep learning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "\n",
    "#Updating the second classifier\n",
    "net.classifier[4] = nn.Linear(4096,1024)\n",
    "\n",
    "#Updating the third and the last classifier that is the output layer of the network. Make sure to have 10 output nodes if we are going to get 10 class labels through our model.\n",
    "net.classifier[6] = nn.Linear(1024,10)\n",
    "\n",
    "net.load_state_dict(torch.load(\"./2.model.path\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec35a2",
   "metadata": {},
   "source": [
    "**Open the Image and preprocess**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c145de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Torchvision module contains various utilities, classes, models and datasets \n",
    "# used towards computer vision usecases\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# Functional module contains helper functions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "ind = 3\n",
    "\n",
    "X = images[ind].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9de48",
   "metadata": {},
   "source": [
    "**Retrieve the gradient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e625dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "# Set the requires_grad_ to the image for retrieving gradients\n",
    "X.requires_grad_()\n",
    "\n",
    "\n",
    "saliency = None\n",
    "\n",
    "# Retrieve output from the image\n",
    "output = net(X)\n",
    "\n",
    "\n",
    "# Catch the output\n",
    "output_idx = output.argmax()\n",
    "output_max = output[0, output_idx]\n",
    "\n",
    "# Do backpropagation to get the derivative \n",
    "# of the output based on the image\n",
    "output_max.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfcebad",
   "metadata": {},
   "source": [
    "**Visualize the Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# Retireve the saliency map and also pick the maximum value from channels on each pixel.\n",
    "# In this case, we look at dim=1. Recall the shape (batch_size, channel, width, height)\n",
    "saliency, _ = torch.max(X.grad.data.abs(), dim=1) \n",
    "saliency = saliency.reshape(224, 224)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef790f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 224, 224)\n",
    "\n",
    "# Visualize the image and the saliency map\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(X.detach().numpy().transpose(1, 2, 0))\n",
    "ax[0].axis('off')\n",
    "\n",
    "#blue correspond to negative, white correspond to positive, and red is zero\n",
    "ax[1].imshow(saliency, cmap='bwr')\n",
    "ax[1].axis('off')\n",
    "plt.tight_layout()\n",
    "fig.suptitle('The Image and Its Saliency Map')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3380fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X.detach().numpy().transpose(1, 2, 0))\n",
    "plt.imshow(saliency, cmap='bwr', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9096097",
   "metadata": {},
   "source": [
    "Useful Resources: <br>\n",
    "https://www.youtube.com/watch?v=0QLrRyLndFI <br>\n",
    "https://www.youtube.com/watch?v=sub-0ZE5Xoo <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
